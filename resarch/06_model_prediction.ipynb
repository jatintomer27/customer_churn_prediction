{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d1eacd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jatin/Projects/customer_churn_prediction/resarch'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33e0d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jatin/Projects/customer_churn_prediction'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42bb83b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelPredictionConfig:\n",
    "    \"\"\"\n",
    "    Storing configuration related to the model evaluation.\n",
    "    \"\"\"\n",
    "    root_dir: Path\n",
    "    encoder_file: Path\n",
    "    status_file: Path\n",
    "    model_path: Path\n",
    "    schema: dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0db3668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_churn_prediction.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH, SCHEMA_FILE_PATH \n",
    "from customer_churn_prediction.utils.common import create_directory, read_yaml\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    Handles loading and managing configuration, \n",
    "    parameters and schema for the project.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_path=CONFIG_FILE_PATH,\n",
    "            schema_path=SCHEMA_FILE_PATH,\n",
    "            params_path=PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_path)\n",
    "        self.schema = read_yaml(schema_path)\n",
    "        self.params = read_yaml(params_path)\n",
    "\n",
    "        create_directory([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_prediction_config(self)->ModelPredictionConfig:\n",
    "        \"\"\"\n",
    "        Return the Model Predictor config\n",
    "        \"\"\"\n",
    "        transformation_config = self.config.data_transformation\n",
    "        config = self.config.model_prediction\n",
    "        schema = self.schema.COLUMNS\n",
    "\n",
    "        create_directory([config.root_dir])\n",
    "\n",
    "        model_predictor_config = ModelPredictionConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            encoder_file = transformation_config.encoder_file,\n",
    "            status_file = config.status_file,\n",
    "            model_path = config.model_path,\n",
    "            schema = schema\n",
    "        )\n",
    "        return model_predictor_config\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f954a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "\n",
    "from customer_churn_prediction import logger\n",
    "\n",
    "class ModelPrediction:\n",
    "    def __init__(self, config: ModelPredictionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def validate_data(self,data: pd.DataFrame):\n",
    "        try:\n",
    "            data_columns = data.dtypes.astype(str).to_dict()\n",
    "            schema = self.config.schema\n",
    "            msg = \"\"\n",
    "            valiation_status = True\n",
    "            for column_name,datatype in schema.items():\n",
    "                if data_columns.get(column_name):\n",
    "                    valiation_status = True if valiation_status else False\n",
    "                    if data_columns.get(column_name) == datatype:\n",
    "                        valiation_status = True if valiation_status else False\n",
    "                        msg += f\"{column_name} validated along with datatype\"\n",
    "                    else:\n",
    "                        valiation_status = False\n",
    "                        msg += f\"{column_name} validated without datatype\"\n",
    "                else:\n",
    "                    valiation_status = False\n",
    "                    msg += f\"{column_name} not validated\"\n",
    "                msg += \"\\n\"\n",
    "            with open(self.config.status_file,'w+') as f:\n",
    "                f.write(f\"Validation status: {valiation_status}\")\n",
    "            logger.info(f\"Model Prediction stage data validation: \\n {msg}\")\n",
    "        except Exception:\n",
    "            logger.exception(f\"Exception occured while validating the columns\")\n",
    "            return \"Something went wrong\"\n",
    "        else:\n",
    "            return msg\n",
    "\n",
    "    def pre_process_data(self, data: pd.DataFrame):\n",
    "        msg, is_data_processed, relevant_data = '', False, pd.DataFrame()\n",
    "        \n",
    "        status = False\n",
    "        with open(self.config.status_file,'r+') as f:\n",
    "            status_file_data = f.read()\n",
    "            if status_file_data:\n",
    "                status = status_file_data.rsplit(\" \",1)\n",
    "        if status:\n",
    "            with open(self.config.encoder_file,\"rb\") as f:\n",
    "                encoders = pickle.load(f)\n",
    "                print(f\"============================={[encoders]}\")\n",
    "                for col, encoder in encoders.items():\n",
    "                    if col in data.columns:\n",
    "                        data[col] = encoder.transform(data[col])\n",
    "            relevant_data = data[list(self.config.schema.keys())]\n",
    "            msg = \"Data processed successfully\"\n",
    "            is_data_processed = True\n",
    "        else:\n",
    "            msg = \"Data columns are not validated\"\n",
    "            is_data_processed = False\n",
    "        return msg, is_data_processed, relevant_data \n",
    "\n",
    "    def predict(self, data: pd.DataFrame):\n",
    "        status, msg = True, ''          \n",
    "        validation_msg = self.validate_data(data)\n",
    "        processing_msg, is_data_processed, relevant_data = self.pre_process_data(data)\n",
    "        if is_data_processed:\n",
    "            model = joblib.load(Path(self.config.model_path))\n",
    "            prediction = model.predict(relevant_data)\n",
    "            return status, prediction, msg\n",
    "        else:\n",
    "            status = False\n",
    "            msg = processing_msg\n",
    "            prediction = False\n",
    "        return status, prediction, msg\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5264d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"gender\": \"Female\",\n",
    "    \"SeniorCitizen\": 0,\n",
    "    \"Partner\": \"Yes\",\n",
    "    \"Dependents\": \"No\",\n",
    "    \"tenure\": 1,\n",
    "    \"PhoneService\": \"No\",\n",
    "    \"MultipleLines\": \"No phone service\",\n",
    "    \"InternetService\": \"DSL\",\n",
    "    \"OnlineSecurity\": \"No\",\n",
    "    \"OnlineBackup\": \"Yes\",\n",
    "    \"DeviceProtection\": \"No\",\n",
    "    \"TechSupport\": \"No\",\n",
    "    \"StreamingTV\": \"No\",\n",
    "    \"StreamingMovies\": \"No\",\n",
    "    \"Contract\": \"Month-to-month\",\n",
    "    \"PaperlessBilling\": \"Yes\",\n",
    "    \"PaymentMethod\": \"Electronic check\",\n",
    "    \"MonthlyCharges\": 29.85,\n",
    "    \"TotalCharges\": '29.85',\n",
    "    \"Churn\":'Yes'\n",
    "}\n",
    "\n",
    "data = pd.DataFrame([data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a401f459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-03 13:12:10,508]:INFO:common.py:Yaml file: config/config.yaml is loaded successfully\n",
      "[2026-01-03 13:12:10,515]:INFO:common.py:Yaml file: schema.yaml is loaded successfully\n",
      "[2026-01-03 13:12:10,522]:INFO:common.py:Yaml file: params.yaml is loaded successfully\n",
      "[2026-01-03 13:12:10,524]:INFO:common.py:Directory created at: artifacts\n",
      "[2026-01-03 13:12:10,525]:INFO:common.py:Directory created at: artifacts/model_prediction\n",
      "[2026-01-03 13:12:10,528]:INFO:2150127475.py:Model Prediction stage data validation: \n",
      " gender validated along with datatype\n",
      "SeniorCitizen validated along with datatype\n",
      "Partner validated along with datatype\n",
      "Dependents validated along with datatype\n",
      "tenure validated along with datatype\n",
      "PhoneService validated along with datatype\n",
      "MultipleLines validated along with datatype\n",
      "InternetService validated along with datatype\n",
      "OnlineSecurity validated along with datatype\n",
      "OnlineBackup validated along with datatype\n",
      "DeviceProtection validated along with datatype\n",
      "TechSupport validated along with datatype\n",
      "StreamingTV validated along with datatype\n",
      "StreamingMovies validated along with datatype\n",
      "Contract validated along with datatype\n",
      "PaperlessBilling validated along with datatype\n",
      "PaymentMethod validated along with datatype\n",
      "MonthlyCharges validated along with datatype\n",
      "TotalCharges validated along with datatype\n",
      "\n",
      "=============================[{'gender': LabelEncoder(), 'Partner': LabelEncoder(), 'Dependents': LabelEncoder(), 'PhoneService': LabelEncoder(), 'MultipleLines': LabelEncoder(), 'InternetService': LabelEncoder(), 'OnlineSecurity': LabelEncoder(), 'OnlineBackup': LabelEncoder(), 'DeviceProtection': LabelEncoder(), 'TechSupport': LabelEncoder(), 'StreamingTV': LabelEncoder(), 'StreamingMovies': LabelEncoder(), 'Contract': LabelEncoder(), 'PaperlessBilling': LabelEncoder(), 'PaymentMethod': LabelEncoder(), 'TotalCharges': LabelEncoder(), 'Churn': LabelEncoder()}]\n",
      "[2026-01-03 13:12:11,209]:ERROR:1307293666.py:Exception occured while executing the model evaluation pipeline\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_63222/1307293666.py\", line 5, in <module>\n",
      "    status, prediction, msg = model_prediction.predict(data)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_63222/2150127475.py\", line 68, in predict\n",
      "    model = joblib.load(Path(self.config.model_path))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jatin/anaconda3/envs/customer_churn/lib/python3.11/site-packages/joblib/numpy_pickle.py\", line 735, in load\n",
      "    with open(filename, \"rb\") as f:\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'artifacts/model_trainer/model.joblib'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'artifacts/model_trainer/model.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m     data_prediction_config = config.get_prediction_config()\n\u001b[32m      4\u001b[39m     model_prediction = ModelPrediction(data_prediction_config)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     status, prediction, msg = \u001b[43mmodel_prediction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# print(f\"============================={[status, prediction, msg]}\")\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mModelPrediction.predict\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     66\u001b[39m processing_msg, is_data_processed, relevant_data = \u001b[38;5;28mself\u001b[39m.pre_process_data(data)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_data_processed:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     model = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     prediction = model.predict(relevant_data)\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m status, prediction, msg\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/customer_churn/lib/python3.11/site-packages/joblib/numpy_pickle.py:735\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    733\u001b[39m         obj = _unpickle(fobj, ensure_native_byte_order=ensure_native_byte_order)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[32m    737\u001b[39m             fobj,\n\u001b[32m    738\u001b[39m             validated_mmap_mode,\n\u001b[32m    739\u001b[39m         ):\n\u001b[32m    740\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    741\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    742\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    743\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'artifacts/model_trainer/model.joblib'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_prediction_config = config.get_prediction_config()\n",
    "    model_prediction = ModelPrediction(data_prediction_config)\n",
    "    status, prediction, msg = model_prediction.predict(data)\n",
    "    # print(f\"============================={[status, prediction, msg]}\")\n",
    "except Exception:\n",
    "    logger.exception(\n",
    "        f\"Exception occured while executing the model evaluation pipeline\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd01b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedf2d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd13fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customer_churn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
