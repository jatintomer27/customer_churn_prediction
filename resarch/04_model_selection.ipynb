{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e55cea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jatin/Projects'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb3fd40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d1c2c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    \"\"\"\n",
    "    Storing configuration related to the model trainer.\n",
    "    \"\"\"\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    model_name: str\n",
    "    params: dict\n",
    "    target_column: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1678f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configuration manager module for the Customer Churn Prediction project.\n",
    "Handles loading and managing project configuration, parameters, and schema.\n",
    "\"\"\"\n",
    "\n",
    "from customer_churn_prediction.constants import (\n",
    "    CONFIG_FILE_PATH, \n",
    "    PARAMS_FILE_PATH,\n",
    "    SCHEMA_FILE_PATH \n",
    ")\n",
    "from customer_churn_prediction.entity.config_entity import (\n",
    "    DataIngestionConfig,\n",
    "    DataValidationConfig,\n",
    "    DataTransformationConfig,\n",
    "    ModelTrainerConfig\n",
    ")\n",
    "from customer_churn_prediction.utils.common import create_directory, read_yaml\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    Handles loading and managing configuration, \n",
    "    parameters and schema for the project.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_path=CONFIG_FILE_PATH,\n",
    "            schema_path=SCHEMA_FILE_PATH,\n",
    "            params_path=PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_path)\n",
    "        self.schema = read_yaml(schema_path)\n",
    "        self.params = read_yaml(params_path)\n",
    "\n",
    "        create_directory([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        \"\"\"\n",
    "        Return Data Ingestion configuration.\n",
    "        \"\"\"\n",
    "        config = self.config.data_ingestion\n",
    "        create_directory([config.root_dir])\n",
    "        \n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            kaggle_dataset = config.kaggle_dataset,\n",
    "            file = config.file,\n",
    "            local_data_file = config.local_data_file,\n",
    "            data_dir = config.data_dir\n",
    "        )\n",
    "        return data_ingestion_config\n",
    "\n",
    "    def get_data_validation_config(self)-> DataValidationConfig:\n",
    "        \"\"\"\n",
    "        Return Data validation configuration.\n",
    "        \"\"\"\n",
    "        config = self.config.data_validation\n",
    "        schema = self.schema.COLUMNS\n",
    "        create_directory([config.root_dir])\n",
    "\n",
    "        data_validation_config = DataValidationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            local_data_file=config.local_data_file,\n",
    "            status_file=config.status_file,\n",
    "            status_message_file=config.status_message_file,\n",
    "            all_schema=schema\n",
    "        )\n",
    "        return data_validation_config\n",
    "    \n",
    "    def get_data_transformation_config(self)-> DataTransformationConfig:\n",
    "        \"\"\"\n",
    "        Return data transformation config\n",
    "        \"\"\"\n",
    "        config = self.config.data_transformation\n",
    "        schema = self.schema.COLUMNS\n",
    "        target_column = self.schema.TARGET_COLUMN\n",
    "        params = self.params\n",
    "        create_directory([config.root_dir])\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            local_data_file=config.local_data_file,\n",
    "            filtered_data_file=config.filtered_data_file,\n",
    "            encoded_data_file=config.encoded_data_file,\n",
    "            encoder_file=config.encoder_file,\n",
    "            schema=schema,\n",
    "            target_column=target_column,\n",
    "            params=params\n",
    "        )\n",
    "        return data_transformation_config\n",
    "    \n",
    "    def get_model_trainer_config(self)-> ModelTrainerConfig:\n",
    "        \"\"\"\n",
    "        Train the multiple models and pick the best one\n",
    "        \"\"\"\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params\n",
    "        target_column = self.schema.TARGET_COLUMN\n",
    "        create_directory([config.root_dir])\n",
    "        model_trainer = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_name=config.model_name,\n",
    "            params=params,\n",
    "            target_column=target_column.name\n",
    "        )\n",
    "        return model_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "feca4f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-17 22:02:02,460]:INFO:common.py:Yaml file: config/config.yaml is loaded successfully\n",
      "[2026-01-17 22:02:02,466]:INFO:common.py:Yaml file: schema.yaml is loaded successfully\n",
      "[2026-01-17 22:02:02,475]:INFO:common.py:Yaml file: params.yaml is loaded successfully\n",
      "[2026-01-17 22:02:02,478]:INFO:common.py:Directory created at: artifacts\n",
      "[2026-01-17 22:02:02,480]:INFO:common.py:Directory created at: artifacts/model_trainer\n"
     ]
    }
   ],
   "source": [
    "configuration_manager = ConfigurationManager()\n",
    "model_selection_config = configuration_manager.get_model_trainer_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a16fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model Trainer component to trains multiple models with different hyperparameters\n",
    "and selects the best one based on evaluation metrics.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import importlib\n",
    "import itertools\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from customer_churn_prediction import logger\n",
    "from customer_churn_prediction.entity.config_entity import ModelTrainerConfig\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def _get_class_from_string(self, full_class_path):\n",
    "        \"\"\"\n",
    "        Dynamically import model class.\n",
    "        \"\"\"\n",
    "        module_name, class_name = full_class_path.rsplit('.',1)\n",
    "        module = importlib.import_module(module_name)\n",
    "        return getattr(module, class_name)\n",
    "    \n",
    "    def load_train_test_split(self):\n",
    "        \"\"\"\n",
    "        Load and split the training and testing datasets into features and target variables.\n",
    "        \"\"\"\n",
    "        train_data = pd.read_csv(self.config.train_data_path)\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "        train_x = train_data.drop([self.config.target_column],axis=1)\n",
    "        train_y = train_data[self.config.target_column]\n",
    "\n",
    "        test_x = test_data.drop([self.config.target_column],axis=1)\n",
    "        test_y = test_data[self.config.target_column]\n",
    "\n",
    "        return train_x, train_y, test_x, test_y\n",
    "\n",
    "    \n",
    "    def train_and_select_best_model(self):\n",
    "        \"\"\"\n",
    "        Train specified models and return the best one.\n",
    "        \"\"\"\n",
    "        best_model = None\n",
    "        best_score = - np.inf\n",
    "        best_model_name = None\n",
    "        train_x, train_y, test_x, test_y = self.load_train_test_split()\n",
    "        for model_name, model_config in self.config.params.models.items():\n",
    "            model_class = self._get_class_from_string(model_config.model_class)\n",
    "            param_grid = model_config.params\n",
    "\n",
    "            keys, values = zip(*param_grid.items())\n",
    "            for combination in itertools.product(*values):\n",
    "                params_dict = dict(zip(keys, combination))\n",
    "                model = model_class(**params_dict)\n",
    "\n",
    "                model.fit(train_x,train_y)\n",
    "                y_pred = model.predict(test_x)\n",
    "\n",
    "                score = recall_score(test_y, y_pred) # As our False Negative is more important in this usecase\n",
    "\n",
    "                logger.info(f\"{model_name} | Params: {params_dict} | F1: {score:.4f}\")\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_model = model\n",
    "                    best_model_name = model_name\n",
    "        logger.info(f\"Best model: {best_model_name} with F1-score={best_score:.4f}\")\n",
    "        joblib.dump(best_model, os.path.join(self.config.root_dir,self.config.model_name))\n",
    "        logger.info(f\"Best model saved at: {os.path.join(self.config.root_dir,self.config.model_name)}\")\n",
    "        return best_model, best_model_name, best_score\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bd77ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-17 21:54:06,511]:INFO:common.py:Yaml file: config/config.yaml is loaded successfully\n",
      "[2026-01-17 21:54:06,516]:INFO:common.py:Yaml file: schema.yaml is loaded successfully\n",
      "[2026-01-17 21:54:06,525]:INFO:common.py:Yaml file: params.yaml is loaded successfully\n",
      "[2026-01-17 21:54:06,527]:INFO:common.py:Directory created at: artifacts\n",
      "[2026-01-17 21:54:06,529]:INFO:common.py:Directory created at: artifacts/model_trainer\n",
      "[2026-01-17 21:54:06,530]:ERROR:305617296.py:Exception occured while executing the model training and selection pipeline\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_47400/305617296.py\", line 7, in <module>\n",
      "    model_selection_config = config.get_model_trainer_config()\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_47400/741302221.py\", line 99, in get_model_trainer_config\n",
      "    model_trainer = ModelTrainerConfig(\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ModelTrainerConfig.__init__() got an unexpected keyword argument 'params'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ModelTrainerConfig.__init__() got an unexpected keyword argument 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      6\u001b[39m     config = ConfigurationManager()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     model_selection_config = \u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_model_trainer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     model_trainer = ModelTrainer(model_selection_config)\n\u001b[32m      9\u001b[39m     model_trainer.train_and_select_best_model()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36mConfigurationManager.get_model_trainer_config\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     97\u001b[39m target_column = \u001b[38;5;28mself\u001b[39m.schema.TARGET_COLUMN\n\u001b[32m     98\u001b[39m create_directory([config.root_dir])\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m model_trainer = \u001b[43mModelTrainerConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_data_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_data_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest_data_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_trainer\n",
      "\u001b[31mTypeError\u001b[39m: ModelTrainerConfig.__init__() got an unexpected keyword argument 'params'"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "\n",
    "from customer_churn_prediction import logger\n",
    "\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_selection_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(model_selection_config)\n",
    "    model_trainer.train_and_select_best_model()\n",
    "except Exception:\n",
    "    logger.exception(\n",
    "        f\"Exception occured while executing the model training and selection pipeline\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a4fbcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jatin/Projects/customer_churn_prediction\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a0e1cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-17 21:24:24,048]:INFO:common.py:Yaml file: params.yaml is loaded successfully\n"
     ]
    }
   ],
   "source": [
    "data = read_yaml(Path('params.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df80430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logistic_regression': {'model_class': 'sklearn.linear_model.LogisticRegression', 'params': {'C': [0.01, 0.1, 1.0, 10.0], 'solver': ['liblinear', 'lbfgs']}}, 'random_forest': {'model_class': 'sklearn.ensemble.RandomForestClassifier', 'params': {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 20]}}, 'xgboost': {'model_class': 'xgboost.XGBClassifier', 'params': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 0.2]}}}\n"
     ]
    }
   ],
   "source": [
    "print(data.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f800010b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('C', BoxList([0.01, 0.1, 1.0, 10.0])), ('solver', BoxList(['liblinear', 'lbfgs']))])\n",
      "dict_items([('n_estimators', BoxList([50, 100, 200])), ('max_depth', BoxList([5, 10, 20]))])\n",
      "dict_items([('n_estimators', BoxList([100, 200])), ('learning_rate', BoxList([0.01, 0.1, 0.2]))])\n"
     ]
    }
   ],
   "source": [
    "for model,model_config in data.models.items():\n",
    "    print(model_config.params.items())\n",
    "    # keys, values = zip(*model_config.params.items())\n",
    "    # print(f\"{keys = }, {values = }\")\n",
    "    # for param, values in model_config.params.items():\n",
    "    #     print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e73815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d332329e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46f157a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customer_churn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
