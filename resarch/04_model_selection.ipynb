{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e55cea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jatin/Projects/customer_churn_prediction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3fd40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d1c2c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    \"\"\"\n",
    "    Storing configuration related to the model trainer.\n",
    "    \"\"\"\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    model_name: str\n",
    "    params: dict\n",
    "    target_column: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1678f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configuration manager module for the Customer Churn Prediction project.\n",
    "Handles loading and managing project configuration, parameters, and schema.\n",
    "\"\"\"\n",
    "\n",
    "from customer_churn_prediction.constants import (\n",
    "    CONFIG_FILE_PATH, \n",
    "    PARAMS_FILE_PATH,\n",
    "    SCHEMA_FILE_PATH \n",
    ")\n",
    "from customer_churn_prediction.entity.config_entity import (\n",
    "    DataIngestionConfig,\n",
    "    DataValidationConfig,\n",
    "    DataTransformationConfig,\n",
    "    ModelTrainerConfig\n",
    ")\n",
    "from customer_churn_prediction.utils.common import create_directory, read_yaml\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    Handles loading and managing configuration, \n",
    "    parameters and schema for the project.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_path=CONFIG_FILE_PATH,\n",
    "            schema_path=SCHEMA_FILE_PATH,\n",
    "            params_path=PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_path)\n",
    "        self.schema = read_yaml(schema_path)\n",
    "        self.params = read_yaml(params_path)\n",
    "\n",
    "        create_directory([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        \"\"\"\n",
    "        Return Data Ingestion configuration.\n",
    "        \"\"\"\n",
    "        config = self.config.data_ingestion\n",
    "        create_directory([config.root_dir])\n",
    "        \n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            kaggle_dataset = config.kaggle_dataset,\n",
    "            file = config.file,\n",
    "            local_data_file = config.local_data_file,\n",
    "            data_dir = config.data_dir\n",
    "        )\n",
    "        return data_ingestion_config\n",
    "\n",
    "    def get_data_validation_config(self)-> DataValidationConfig:\n",
    "        \"\"\"\n",
    "        Return Data validation configuration.\n",
    "        \"\"\"\n",
    "        config = self.config.data_validation\n",
    "        schema = self.schema.COLUMNS\n",
    "        create_directory([config.root_dir])\n",
    "\n",
    "        data_validation_config = DataValidationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            local_data_file=config.local_data_file,\n",
    "            status_file=config.status_file,\n",
    "            status_message_file=config.status_message_file,\n",
    "            all_schema=schema\n",
    "        )\n",
    "        return data_validation_config\n",
    "    \n",
    "    def get_data_transformation_config(self)-> DataTransformationConfig:\n",
    "        \"\"\"\n",
    "        Return data transformation config\n",
    "        \"\"\"\n",
    "        config = self.config.data_transformation\n",
    "        schema = self.schema.COLUMNS\n",
    "        target_column = self.schema.TARGET_COLUMN\n",
    "        params = self.params\n",
    "        create_directory([config.root_dir])\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            local_data_file=config.local_data_file,\n",
    "            filtered_data_file=config.filtered_data_file,\n",
    "            encoded_data_file=config.encoded_data_file,\n",
    "            encoder_file=config.encoder_file,\n",
    "            schema=schema,\n",
    "            target_column=target_column,\n",
    "            params=params\n",
    "        )\n",
    "        return data_transformation_config\n",
    "    \n",
    "    def get_model_trainer_config(self)-> ModelTrainerConfig:\n",
    "        \"\"\"\n",
    "        Train the multiple models and pick the best one\n",
    "        \"\"\"\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params\n",
    "        target_column = self.schema.TARGET_COLUMN\n",
    "        create_directory([config.root_dir])\n",
    "        model_trainer = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_name=config.model_name,\n",
    "            params=params,\n",
    "            target_column=target_column.name\n",
    "        )\n",
    "        return model_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feca4f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-02 09:53:44,742]:INFO:common.py:Yaml file: config/config.yaml is loaded successfully\n",
      "[2025-11-02 09:53:44,746]:INFO:common.py:Yaml file: schema.yaml is loaded successfully\n",
      "[2025-11-02 09:53:44,750]:INFO:common.py:Yaml file: params.yaml is loaded successfully\n",
      "[2025-11-02 09:53:44,751]:INFO:common.py:Directory created at: artifacts\n",
      "[2025-11-02 09:53:44,752]:INFO:common.py:Directory created at: artifacts/model_trainer\n"
     ]
    }
   ],
   "source": [
    "configuration_manager = ConfigurationManager()\n",
    "model_selection_config = configuration_manager.get_model_trainer_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79de46c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from customer_churn_prediction.constants import *\n",
    "from customer_churn_prediction.utils.common import create_directory, read_yaml\n",
    "\n",
    "y = read_yaml(PARAMS_FILE_PATH)\n",
    "for model_name, model_config in y.models.items():\n",
    "    # print(model_name)\n",
    "    # print(model_config)\n",
    "    # print(model_config.params)\n",
    "    # print(model_config.params.items())\n",
    "    # print(*model_config.params.items())\n",
    "    # print(zip(*model_config.params.items()))\n",
    "    keys,values = zip(*model_config.params.items())\n",
    "    for combination in itertools.product(*values):\n",
    "        # print(combination)\n",
    "        params_dict = dict(zip(keys, combination))\n",
    "        print(params_dict)\n",
    "        # model = model_class(**params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a16fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model Trainer component to trains multiple models with different hyperparameters\n",
    "and selects the best one based on evaluation metrics.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import importlib\n",
    "import itertools\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from customer_churn_prediction import logger\n",
    "from customer_churn_prediction.entity.config_entity import ModelTrainerConfig\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def _get_class_from_string(self, full_class_path):\n",
    "        \"\"\"\n",
    "        Dynamically import model class.\n",
    "        \"\"\"\n",
    "        module_name, class_name = full_class_path.rsplit('.',1)\n",
    "        module = importlib.import_module(module_name)\n",
    "        return getattr(module, class_name)\n",
    "    \n",
    "    def load_train_test_split(self):\n",
    "        \"\"\"\n",
    "        Load and split the training and testing datasets into features and target variables.\n",
    "        \"\"\"\n",
    "        train_data = pd.read_csv(self.config.train_data_path)\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "        train_x = train_data.drop([self.config.target_column],axis=1)\n",
    "        train_y = train_data[self.config.target_column]\n",
    "\n",
    "        test_x = test_data.drop([self.config.target_column],axis=1)\n",
    "        test_y = test_data[self.config.target_column]\n",
    "\n",
    "        return train_x, train_y, test_x, test_y\n",
    "\n",
    "    \n",
    "    def train_and_select_best_model(self):\n",
    "        \"\"\"\n",
    "        Train specified models and return the best one.\n",
    "        \"\"\"\n",
    "        best_model = None\n",
    "        best_score = - np.inf\n",
    "        best_model_name = None\n",
    "        train_x, train_y, test_x, test_y = self.load_train_test_split()\n",
    "        for model_name, model_config in self.config.params.models.items():\n",
    "            model_class = self._get_class_from_string(model_config.model_class)\n",
    "            param_grid = model_config.params\n",
    "\n",
    "            keys, values = zip(*param_grid.items())\n",
    "            for combination in itertools.product(*values):\n",
    "                params_dict = dict(zip(keys, combination))\n",
    "                model = model_class(**params_dict)\n",
    "\n",
    "                model.fit(train_x,train_y)\n",
    "                y_pred = model.predict(test_x)\n",
    "\n",
    "                score = recall_score(test_y, y_pred) # As our False Negative is more important in this usecase\n",
    "\n",
    "                logger.info(f\"{model_name} | Params: {params_dict} | F1: {score:.4f}\")\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_model = model\n",
    "                    best_model_name = model_name\n",
    "        logger.info(f\"Best model: {best_model_name} with F1-score={best_score:.4f}\")\n",
    "        joblib.dump(best_model, os.path.join(self.config.root_dir,self.config.model_name))\n",
    "        logger.info(f\"Best model saved at: {os.path.join(self.config.root_dir,self.config.model_name)}\")\n",
    "        return best_model, best_model_name, best_score\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd77ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-02 09:34:14,700]:INFO:common.py:Yaml file: config/config.yaml is loaded successfully\n",
      "[2025-11-02 09:34:14,704]:INFO:common.py:Yaml file: schema.yaml is loaded successfully\n",
      "[2025-11-02 09:34:14,708]:INFO:common.py:Yaml file: params.yaml is loaded successfully\n",
      "[2025-11-02 09:34:14,710]:INFO:common.py:Directory created at: artifacts\n",
      "[2025-11-02 09:34:14,710]:INFO:common.py:Directory created at: artifacts/model_trainer\n",
      "(7800, 20)\n",
      "(7800,)\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "\n",
    "from customer_churn_prediction import logger\n",
    "\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_selection_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(model_selection_config)\n",
    "    model_trainer.train_and_select_best_model()\n",
    "except Exception:\n",
    "    logger.exception(\n",
    "        f\"Exception occured while executing the model training and selection pipeline\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4fbcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e1cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800010b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e73815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d332329e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46f157a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customer_churn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
